#!/usr/bin/env python3
"""
Script phÃ¢n tÃ­ch chi tiáº¿t káº¿t quáº£ vÃ  Ä‘á» xuáº¥t cáº£i thiá»‡n
"""

import json
import pandas as pd
import numpy as np
from pathlib import Path

def analyze_results(results_file='evaluation_results.json'):
    """PhÃ¢n tÃ­ch chi tiáº¿t káº¿t quáº£ Ä‘Ã¡nh giÃ¡"""
    
    with open(results_file, 'r') as f:
        results = json.load(f)
    
    print("ğŸ” PHÃ‚N TÃCH CHI TIáº¾T Káº¾T QUáº¢")
    print("=" * 80)
    
    # TÃ­nh toÃ¡n Ä‘á»™ giáº£m hiá»‡u suáº¥t
    performance_analysis = []
    
    for model_name, model_results in results.items():
        if model_results['pretrained'] and model_results['finetuned']:
            pretrained = model_results['pretrained']
            finetuned = model_results['finetuned']
            
            for metric in pretrained.keys():
                pretrained_score = pretrained[metric]
                finetuned_score = finetuned[metric]
                
                # TÃ­nh % thay Ä‘á»•i
                change = finetuned_score - pretrained_score
                change_pct = (change / pretrained_score) * 100
                
                performance_analysis.append({
                    'Model': model_name,
                    'Metric': metric,
                    'Pretrained': pretrained_score,
                    'Finetuned': finetuned_score,
                    'Change': change,
                    'Change %': change_pct
                })
    
    df = pd.DataFrame(performance_analysis)
    
    # Hiá»ƒn thá»‹ káº¿t quáº£ theo tá»«ng metric
    metrics = ['HitRate@1', 'HitRate@5', 'HitRate@10', 'MRR@1', 'MRR@5', 'MRR@10']
    
    for metric in metrics:
        print(f"\nğŸ“Š {metric} - Performance Change:")
        print("-" * 60)
        
        metric_df = df[df['Metric'] == metric].copy()
        metric_df = metric_df.sort_values('Change %', ascending=False)
        
        for _, row in metric_df.iterrows():
            change_symbol = "ğŸ“ˆ" if row['Change %'] > 0 else "ğŸ“‰"
            print(f"{change_symbol} {row['Model']:20} | "
                  f"Pre: {row['Pretrained']:.4f} | "
                  f"Fine: {row['Finetuned']:.4f} | "
                  f"Change: {row['Change %']:+6.2f}%")
    
    # Thá»‘ng kÃª tá»•ng quan
    print(f"\nğŸ“ˆ THá»NG KÃŠ Tá»”NG QUAN:")
    print("=" * 80)
    
    avg_change = df['Change %'].mean()
    worst_change = df['Change %'].min()
    best_change = df['Change %'].max()
    
    print(f"ğŸ“Š Thay Ä‘á»•i trung bÃ¬nh: {avg_change:.2f}%")
    print(f"ğŸ“‰ Thay Ä‘á»•i tá»‡ nháº¥t: {worst_change:.2f}%")
    print(f"ğŸ“ˆ Thay Ä‘á»•i tá»‘t nháº¥t: {best_change:.2f}%")
    
    # PhÃ¢n tÃ­ch theo model
    print(f"\nğŸ¤– PHÃ‚N TÃCH THEO MODEL:")
    print("=" * 80)
    
    model_avg = df.groupby('Model')['Change %'].mean().sort_values(ascending=False)
    for model, avg_change in model_avg.items():
        symbol = "ğŸ“ˆ" if avg_change > 0 else "ğŸ“‰"
        print(f"{symbol} {model:20} | Average change: {avg_change:+6.2f}%")
    
    # Nháº­n xÃ©t vÃ  Ä‘á» xuáº¥t
    print(f"\nğŸ’¡ NHáº¬N XÃ‰T VÃ€ Äá»€ XUáº¤T:")
    print("=" * 80)
    
    suggestions = []
    
    if avg_change < -10:
        suggestions.append("âŒ Fine-tuning Ä‘ang lÃ m giáº£m hiá»‡u suáº¥t Ä‘Ã¡ng ká»ƒ")
        suggestions.append("ğŸ”§ Äá» xuáº¥t: Giáº£m learning rate (VD: 1e-5 â†’ 1e-6)")
        suggestions.append("ğŸ”§ Äá» xuáº¥t: Sá»­ dá»¥ng frozen backbone + chá»‰ train classification head")
        suggestions.append("ğŸ”§ Äá» xuáº¥t: Ãp dá»¥ng gradual unfreezing")
    
    if worst_change < -30:
        suggestions.append("âš ï¸ CÃ³ model bá»‹ catastrophic forgetting nghiÃªm trá»ng")
        suggestions.append("ğŸ”§ Äá» xuáº¥t: Sá»­ dá»¥ng smaller learning rate cho backbone")
        suggestions.append("ğŸ”§ Äá» xuáº¥t: ThÃªm regularization (weight decay, dropout)")
    
    # Kiá»ƒm tra model nÃ o á»•n Ä‘á»‹nh nháº¥t
    stability_scores = df.groupby('Model')['Change %'].std()
    most_stable = stability_scores.idxmin()
    suggestions.append(f"ğŸ† Model á»•n Ä‘á»‹nh nháº¥t: {most_stable}")
    
    for suggestion in suggestions:
        print(suggestion)
    
    return df

def create_improvement_recommendations():
    """Táº¡o Ä‘á» xuáº¥t cáº£i thiá»‡n cá»¥ thá»ƒ"""
    
    print(f"\nğŸš€ Äá»€ XUáº¤T Cáº¢I THIá»†N Cá»¤ THá»‚:")
    print("=" * 80)
    
    recommendations = [
        {
            "category": "Learning Rate Strategy",
            "suggestions": [
                "Sá»­ dá»¥ng learning rate scheduler (cosine annealing)",
                "Differential learning rates: backbone (1e-6), head (1e-4)",
                "Warmup learning rate trong 10% epochs Ä‘áº§u"
            ]
        },
        {
            "category": "Training Strategy", 
            "suggestions": [
                "Frozen backbone training: freeze backbone, chá»‰ train head",
                "Gradual unfreezing: unfreeze tá»«ng layer má»™t",
                "Data augmentation máº¡nh hÆ¡n Ä‘á»ƒ tÄƒng diversity"
            ]
        },
        {
            "category": "Regularization",
            "suggestions": [
                "Weight decay: 0.01 â†’ 0.001",
                "Dropout trong classification head",
                "Label smoothing vá»›i Î±=0.1"
            ]
        },
        {
            "category": "Loss Function",
            "suggestions": [
                "Thá»­ ContrastiveLoss thay vÃ¬ NT-Xent",
                "Triplet loss vá»›i hard negative mining",
                "Focal loss Ä‘á»ƒ xá»­ lÃ½ class imbalance"
            ]
        },
        {
            "category": "Data Strategy",
            "suggestions": [
                "TÄƒng kÃ­ch thÆ°á»›c dataset náº¿u cÃ³ thá»ƒ",
                "Cross-validation Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ robust",
                "Synthetic data generation tá»« pretrained model"
            ]
        }
    ]
    
    for rec in recommendations:
        print(f"\nğŸ“‹ {rec['category']}:")
        print("-" * 40)
        for i, suggestion in enumerate(rec['suggestions'], 1):
            print(f"  {i}. {suggestion}")

def generate_training_configs():
    """Táº¡o config files cáº£i thiá»‡n"""
    
    print(f"\nâš™ï¸ Táº O CONFIG FILES Cáº¢I THIá»†N:")
    print("=" * 80)
    
    # Config vá»›i frozen backbone
    frozen_config = {
        "model": {
            "freeze_backbone": True,
            "backbone_lr": 0.0,
            "head_lr": 1e-4
        },
        "training": {
            "epochs": 50,
            "warmup_epochs": 5,
            "weight_decay": 0.001,
            "label_smoothing": 0.1
        },
        "optimizer": {
            "type": "AdamW",
            "lr": 1e-4,
            "betas": [0.9, 0.999]
        },
        "scheduler": {
            "type": "CosineAnnealingLR",
            "T_max": 50
        }
    }
    
    # Config vá»›i gradual unfreezing
    gradual_config = {
        "model": {
            "gradual_unfreezing": True,
            "unfreeze_schedule": [10, 20, 30],  # epochs to unfreeze layers
            "backbone_lr": 1e-6,
            "head_lr": 1e-4
        },
        "training": {
            "epochs": 100,
            "warmup_epochs": 10,
            "weight_decay": 0.01,
            "dropout": 0.1
        }
    }
    
    configs = {
        "frozen_backbone": frozen_config,
        "gradual_unfreezing": gradual_config
    }
    
    for name, config in configs.items():
        config_path = f"configs/improved_{name}.yaml"
        print(f"ğŸ“„ Generated: {config_path}")
        
        # Táº¡o YAML content
        yaml_content = f"""# Improved training config - {name}
model:
  backbone: dino_v2
  variant: dinov2_vits14
  num_classes: 4
  feature_dim: 768
  freeze_backbone: {config['model'].get('freeze_backbone', False)}
  
training:
  epochs: {config['training']['epochs']}
  batch_size: 32
  warmup_epochs: {config['training']['warmup_epochs']}
  weight_decay: {config['training']['weight_decay']}
  
optimizer:
  type: AdamW
  backbone_lr: {config['model'].get('backbone_lr', 1e-5)}
  head_lr: {config['model'].get('head_lr', 1e-4)}
  
scheduler:
  type: CosineAnnealingLR
  T_max: {config['training']['epochs']}
  
loss:
  type: ntxent
  temperature: 0.1
  
data:
  path: "data/processed"
  image_size: 224
  normalize: true
  augmentation:
    horizontal_flip: 0.5
    rotation: 15
    color_jitter: 0.2
"""
        
        with open(config_path, 'w') as f:
            f.write(yaml_content)

if __name__ == '__main__':
    # PhÃ¢n tÃ­ch káº¿t quáº£ hiá»‡n táº¡i
    df = analyze_results()
    
    # Táº¡o Ä‘á» xuáº¥t cáº£i thiá»‡n
    create_improvement_recommendations()
    
    # Táº¡o config files cáº£i thiá»‡n
    generate_training_configs()
    
    print(f"\nâœ… PhÃ¢n tÃ­ch hoÃ n táº¥t! ÄÃ£ táº¡o config files cáº£i thiá»‡n.")
