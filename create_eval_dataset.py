#!/usr/bin/env python3
"""
Script táº¡o bá»™ data evaluation cho image retrieval:
- Query: CÃ¡c áº£nh gá»‘c trong táº­p test
- Corpus: ToÃ n bá»™ áº£nh gá»‘c vÃ  áº£nh Ä‘Ã£ augment cá»§a táº­p train, val, vÃ  test
- Ground Truth: Mapping tá»« má»—i query Ä‘áº¿n cÃ¡c phiÃªn báº£n augment tÆ°Æ¡ng á»©ng trong corpus

Output:
- eval_data/
  â”œâ”€â”€ query/                    # áº¢nh test gá»‘c (queries)
  â”œâ”€â”€ corpus/                   # ToÃ n bá»™ áº£nh trong corpus
  â””â”€â”€ ground_truth.json         # Mapping tá»« query Ä‘áº¿n ground truth trong corpus
"""

import yaml
import torch
import torch.utils.data
import pandas as pd
from pathlib import Path
import argparse
import json
from torchvision import transforms
from PIL import Image
import shutil
import os

from src.data_loader import create_dataloaders
from src.utils import set_seed, setup_logging


def get_augmentation_transform_without_normalize(image_size=224, backbone='dinov2'):
    """
    Táº¡o transform vá»›i augmentation máº¡nh nhÆ°ng KHÃ”NG normalize.
    DÃ¹ng Ä‘á»ƒ táº¡o áº£nh augment Ä‘á»ƒ lÆ°u trá»¯.
    """
    return transforms.Compose([
        # BÆ°á»›c 1: Tiá»n xá»­ lÃ½ - Táº­p trung vÃ o vÃ¹ng quan trá»ng (vÃ²ng trÃ²n ná»™i soi)
        transforms.Resize((640, 480)),
        transforms.CenterCrop(size=(450, 450)), # Giáº£ sá»­ áº£nh gá»‘c ~500x500
        transforms.Resize((image_size, image_size)), # Resize vá» kÃ­ch thÆ°á»›c chuáº©n

        # BÆ°á»›c 2: Augmentation hÃ¬nh há»c (MÃ´ phá»ng chuyá»ƒn Ä‘á»™ng cá»§a á»‘ng soi)
        transforms.RandomApply([
            transforms.RandomAffine(
                degrees=20,               # Xoay má»™t gÃ³c há»£p lÃ½
                translate=(0.1, 0.1),     # Dá»‹ch chuyá»ƒn nháº¹
                scale=(0.6, 1.3)          # Zoom vÃ o/ra má»™t chÃºt
            )
        ], p=0.7), # Ãp dá»¥ng vá»›i xÃ¡c suáº¥t 70%

        # BÆ°á»›c 3: Augmentation mÃ u sáº¯c (MÃ´ phá»ng Ä‘iá»u kiá»‡n Ã¡nh sÃ¡ng vÃ  camera khÃ¡c nhau)
        transforms.ColorJitter(
            brightness=0.2,   # Äiá»u chá»‰nh Ä‘á»™ sÃ¡ng
            contrast=0.2,     # Äiá»u chá»‰nh Ä‘á»™ tÆ°Æ¡ng pháº£n
            saturation=0.2,   # Äiá»u chá»‰nh Ä‘á»™ bÃ£o hÃ²a
            hue=0.05          # HUE ráº¥t nháº¡y, chá»‰ nÃªn thay Ä‘á»•i ráº¥t Ã­t
        ),
        
        # CÃ¡c phÃ©p biáº¿n Ä‘á»•i mÃ u sáº¯c an toÃ n khÃ¡c
        transforms.RandomAutocontrast(p=0.2), # Tá»± Ä‘á»™ng tÄƒng cÆ°á»ng Ä‘á»™ tÆ°Æ¡ng pháº£n

        # BÆ°á»›c 4: Augmentation mÃ´ phá»ng nhiá»…u vÃ  che khuáº¥t
        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.5)),

        # Chuyá»ƒn sang Tensor TRÆ¯á»šC khi thá»±c hiá»‡n RandomErasing
        transforms.ToTensor(),

        # XÃ³a má»™t vÃ¹ng nhá» Ä‘á»ƒ mÃ´ phá»ng bá»‹ che khuáº¥t (vÃ­ dá»¥: bá»Ÿi rÃ¡y tai)
        transforms.RandomErasing(
            p=0.8, # Ãp dá»¥ng vá»›i xÃ¡c suáº¥t tháº¥p
            scale=(0.02, 0.08), # XÃ³a má»™t vÃ¹ng nhá»
            ratio=(0.3, 3.3),
            value='random' # Äiá»n vÃ o báº±ng nhiá»…u ngáº«u nhiÃªn thay vÃ¬ mÃ u Ä‘en
        ),
        # KHÃ”NG cÃ³ Normalize á»Ÿ Ä‘Ã¢y!
    ])


def get_standard_transform_without_normalize(image_size=224):
    """
    Táº¡o transform chuáº©n cho áº£nh gá»‘c nhÆ°ng KHÃ”NG normalize.
    """
    return transforms.Compose([
        transforms.Resize((640, 480)),
        transforms.CenterCrop(size=(450, 450)),
        transforms.Resize((image_size, image_size)),
        transforms.ToTensor(),
        # KHÃ”NG cÃ³ Normalize á»Ÿ Ä‘Ã¢y!
    ])


def get_denormalization_transform(backbone='dinov2'):
    """
    Táº¡o transform Ä‘á»ƒ denormalize áº£nh vá» dáº¡ng PIL cÃ³ thá»ƒ lÆ°u Ä‘Æ°á»£c.
    """
    if backbone == 'ent_vit':
        mean = [0.3464, 0.2280, 0.2228]
        std = [0.2520, 0.2128, 0.2093]
    else:
        mean = [0.485, 0.456, 0.406]
        std = [0.229, 0.224, 0.225]
    
    return transforms.Normalize(
        mean=[-mean[0]/std[0], -mean[1]/std[1], -mean[2]/std[2]],
        std=[1/std[0], 1/std[1], 1/std[2]]
    )


def save_images_from_dataloader(dataloader, output_dir, prefix, transform_func=None, backbone='dinov2'):
    """
    LÆ°u áº£nh tá»« dataloader vÃ o thÆ° má»¥c output_dir.
    
    Args:
        dataloader: DataLoader chá»©a áº£nh
        output_dir: ThÆ° má»¥c Ä‘Ã­ch
        prefix: Prefix cho tÃªn file (vÃ­ dá»¥: 'train_', 'val_', 'test_')
        transform_func: HÃ m transform Ä‘á»ƒ Ã¡p dá»¥ng lÃªn áº£nh (náº¿u cÃ³)
        backbone: Loáº¡i backbone Ä‘á»ƒ xÃ¡c Ä‘á»‹nh denormalization
    
    Returns:
        List cÃ¡c path áº£nh Ä‘Ã£ lÆ°u
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    saved_paths = []
    denormalize = get_denormalization_transform(backbone)
    
    image_counter = 0
    
    for batch_idx, (images, labels) in enumerate(dataloader):
        batch_size = images.size(0)
        
        for i in range(batch_size):
            # Láº¥y áº£nh tá»« batch
            img_tensor = images[i].cpu()
            label = labels[i].item()
            
            # Denormalize áº£nh vá» dáº¡ng cÃ³ thá»ƒ convert sang PIL
            img_denormalized = denormalize(img_tensor)
            img_pil = transforms.ToPILImage()(img_denormalized)
            
            # Náº¿u cÃ³ transform_func, Ã¡p dá»¥ng nÃ³
            if transform_func is not None:
                img_tensor_processed = transform_func(img_pil)
                img_pil = transforms.ToPILImage()(img_tensor_processed)
            
            # Táº¡o tÃªn file
            filename = f"{prefix}{image_counter:05d}_class{label}.jpg"
            filepath = output_dir / filename
            
            # LÆ°u áº£nh
            img_pil.save(filepath)
            saved_paths.append(str(filepath))
            
            image_counter += 1
    
    return saved_paths


def create_augmented_images_from_dataloader(dataloader, output_dir, prefix, num_augmentations, backbone='dinov2'):
    """
    Táº¡o vÃ  lÆ°u cÃ¡c phiÃªn báº£n augment cá»§a áº£nh tá»« dataloader.
    
    Args:
        dataloader: DataLoader chá»©a áº£nh
        output_dir: ThÆ° má»¥c Ä‘Ã­ch
        prefix: Prefix cho tÃªn file
        num_augmentations: Sá»‘ lÆ°á»£ng phiÃªn báº£n augment cho má»—i áº£nh
        backbone: Loáº¡i backbone
    
    Returns:
        List cÃ¡c path áº£nh augment Ä‘Ã£ lÆ°u (Ä‘Æ°á»£c group theo áº£nh gá»‘c)
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    augment_transform = get_augmentation_transform_without_normalize(backbone=backbone)
    denormalize = get_denormalization_transform(backbone)
    
    saved_paths = []
    image_counter = 0
    
    for batch_idx, (images, labels) in enumerate(dataloader):
        batch_size = images.size(0)
        
        for i in range(batch_size):
            # Láº¥y áº£nh tá»« batch
            img_tensor = images[i].cpu()
            label = labels[i].item()
            
            # Denormalize áº£nh vá» dáº¡ng cÃ³ thá»ƒ convert sang PIL
            img_denormalized = denormalize(img_tensor)
            img_pil = transforms.ToPILImage()(img_denormalized)
            
            # Táº¡o cÃ¡c phiÃªn báº£n augment
            augmented_paths = []
            for aug_idx in range(num_augmentations):
                # Ãp dá»¥ng augmentation
                img_tensor_aug = augment_transform(img_pil)
                img_pil_aug = transforms.ToPILImage()(img_tensor_aug)
                
                # Táº¡o tÃªn file
                filename = f"{prefix}{image_counter:05d}_aug{aug_idx:02d}_class{label}.jpg"
                filepath = output_dir / filename
                
                # LÆ°u áº£nh
                img_pil_aug.save(filepath)
                augmented_paths.append(str(filepath))
            
            saved_paths.append(augmented_paths)
            image_counter += 1
    
    return saved_paths


def create_evaluation_dataset(config_path, output_dir, num_augmentations=5):
    """
    Táº¡o bá»™ data evaluation hoÃ n chá»‰nh.
    
    Args:
        config_path: ÄÆ°á»ng dáº«n Ä‘áº¿n file config
        output_dir: ThÆ° má»¥c Ä‘Ã­ch
        num_augmentations: Sá»‘ lÆ°á»£ng phiÃªn báº£n augment cho má»—i áº£nh test
    """
    # Load config
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    backbone = config['model']['backbone']
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Táº¡o cÃ¡c thÆ° má»¥c con
    query_dir = output_dir / 'query'
    corpus_dir = output_dir / 'corpus'
    query_dir.mkdir(parents=True, exist_ok=True)
    corpus_dir.mkdir(parents=True, exist_ok=True)
    
    # Load dataloaders
    print("ğŸ“Š Loading dataloaders...")
    train_loader, val_loader, test_loader = create_dataloaders(config['data'], backbone)
    
    # --- 1. Táº¡o Query (Test gá»‘c) ---
    print("ğŸ“Š Creating queries from test set...")
    standard_transform = get_standard_transform_without_normalize()
    query_paths = save_images_from_dataloader(
        test_loader, query_dir, 'query_', standard_transform, backbone
    )
    
    # --- 2. Táº¡o Corpus ---
    print("ğŸ“Š Creating corpus...")
    corpus_paths = []
    corpus_info = []
    
    # Corpus Part 1: áº¢nh gá»‘c tá»« train
    print("  - Adding train set (original)...")
    train_paths = save_images_from_dataloader(
        train_loader, corpus_dir, 'train_orig_', standard_transform, backbone
    )
    corpus_paths.extend(train_paths)
    corpus_info.extend([{'type': 'train_original', 'index': i} for i in range(len(train_paths))])
    
    # Corpus Part 2: áº¢nh gá»‘c tá»« val
    print("  - Adding val set (original)...")
    val_paths = save_images_from_dataloader(
        val_loader, corpus_dir, 'val_orig_', standard_transform, backbone
    )
    corpus_paths.extend(val_paths)
    corpus_info.extend([{'type': 'val_original', 'index': i} for i in range(len(val_paths))])
    
    # Corpus Part 3: áº¢nh augment tá»« train (1 augment má»—i áº£nh)
    print("  - Adding train set (augmented)...")
    train_aug_paths = create_augmented_images_from_dataloader(
        train_loader, corpus_dir, 'train_aug_', 1, backbone
    )
    # Flatten list of lists
    train_aug_flat = [path for paths in train_aug_paths for path in paths]
    corpus_paths.extend(train_aug_flat)
    corpus_info.extend([{'type': 'train_augmented', 'index': i} for i in range(len(train_aug_flat))])
    
    # Corpus Part 4: áº¢nh augment tá»« val (1 augment má»—i áº£nh)
    print("  - Adding val set (augmented)...")
    val_aug_paths = create_augmented_images_from_dataloader(
        val_loader, corpus_dir, 'val_aug_', 1, backbone
    )
    # Flatten list of lists
    val_aug_flat = [path for paths in val_aug_paths for path in paths]
    corpus_paths.extend(val_aug_flat)
    corpus_info.extend([{'type': 'val_augmented', 'index': i} for i in range(len(val_aug_flat))])
    
    # Corpus Part 5: áº¢nh augment tá»« test (ground truth)
    print(f"  - Adding test set (augmented - {num_augmentations} per image)...")
    test_aug_paths = create_augmented_images_from_dataloader(
        test_loader, corpus_dir, 'test_aug_', num_augmentations, backbone
    )
    
    # TÃ­nh toÃ¡n vá»‹ trÃ­ báº¯t Ä‘áº§u cá»§a test augment trong corpus
    test_aug_start_idx = len(corpus_paths)
    
    # Flatten vÃ  thÃªm vÃ o corpus
    test_aug_flat = [path for paths in test_aug_paths for path in paths]
    corpus_paths.extend(test_aug_flat)
    corpus_info.extend([{'type': 'test_augmented', 'index': i} for i in range(len(test_aug_flat))])
    
    # --- 3. Táº¡o Ground Truth Mapping ---
    print("ğŸ“Š Creating ground truth mapping...")
    ground_truth = {}
    
    for query_idx in range(len(query_paths)):
        # TÃ­nh toÃ¡n indices cá»§a cÃ¡c phiÃªn báº£n augment trong corpus
        start_idx = test_aug_start_idx + query_idx * num_augmentations
        end_idx = start_idx + num_augmentations
        
        ground_truth[query_idx] = {
            'query_path': query_paths[query_idx],
            'ground_truth_indices': list(range(start_idx, end_idx)),
            'ground_truth_paths': corpus_paths[start_idx:end_idx]
        }
    
    # --- 4. LÆ°u metadata ---
    print("ğŸ“Š Saving metadata...")
    
    # LÆ°u thÃ´ng tin corpus
    corpus_metadata = {
        'total_corpus_size': len(corpus_paths),
        'corpus_composition': {
            'train_original': len(train_paths),
            'val_original': len(val_paths),
            'train_augmented': len(train_aug_flat),
            'val_augmented': len(val_aug_flat),
            'test_augmented': len(test_aug_flat)
        },
        'corpus_paths': corpus_paths,
        'corpus_info': corpus_info
    }
    
    # LÆ°u thÃ´ng tin query
    query_metadata = {
        'total_queries': len(query_paths),
        'query_paths': query_paths
    }
    
    # LÆ°u ground truth
    ground_truth_metadata = {
        'num_augmentations_per_query': num_augmentations,
        'test_augmented_start_index': test_aug_start_idx,
        'ground_truth_mapping': ground_truth
    }
    
    # LÆ°u cÃ¡c file JSON
    with open(output_dir / 'corpus_metadata.json', 'w', encoding='utf-8') as f:
        json.dump(corpus_metadata, f, indent=2, ensure_ascii=False)
    
    with open(output_dir / 'query_metadata.json', 'w', encoding='utf-8') as f:
        json.dump(query_metadata, f, indent=2, ensure_ascii=False)
    
    with open(output_dir / 'ground_truth.json', 'w', encoding='utf-8') as f:
        json.dump(ground_truth_metadata, f, indent=2, ensure_ascii=False)
    
    # LÆ°u summary
    summary = {
        'config_used': config_path,
        'backbone': backbone,
        'num_augmentations': num_augmentations,
        'statistics': {
            'total_queries': len(query_paths),
            'total_corpus_size': len(corpus_paths),
            'train_original': len(train_paths),
            'val_original': len(val_paths),
            'train_augmented': len(train_aug_flat),
            'val_augmented': len(val_aug_flat),
            'test_augmented': len(test_aug_flat)
        },
        'directory_structure': {
            'query_dir': str(query_dir),
            'corpus_dir': str(corpus_dir),
            'metadata_files': [
                'corpus_metadata.json',
                'query_metadata.json', 
                'ground_truth.json',
                'summary.json'
            ]
        }
    }
    
    with open(output_dir / 'summary.json', 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… Evaluation dataset created successfully!")
    print(f"ğŸ“ Output directory: {output_dir}")
    print(f"ğŸ“Š Statistics:")
    print(f"   - Total queries: {len(query_paths)}")
    print(f"   - Total corpus size: {len(corpus_paths)}")
    print(f"   - Ground truth augmentations per query: {num_augmentations}")
    print(f"   - Test augmented start index: {test_aug_start_idx}")
    
    return summary


def main():
    parser = argparse.ArgumentParser(description='Create evaluation dataset for image retrieval')
    parser.add_argument('--config', '-c', default='configs/dinov2_vits14.yaml', 
                       help='Path to model config file')
    parser.add_argument('--output', '-o', default='eval_data',
                       help='Output directory for evaluation dataset')
    parser.add_argument('--num_augmentations', '-n', type=int, default=5,
                       help='Number of augmentations per test image for ground truth')
    
    args = parser.parse_args()
    
    setup_logging()
    set_seed(42)
    
    print("ğŸš€ Starting evaluation dataset creation...")
    print("=" * 60)
    print(f"ğŸ“ Config: {args.config}")
    print(f"ğŸ“ Output: {args.output}")
    print(f"ğŸ”¢ Augmentations per query: {args.num_augmentations}")
    print("=" * 60)
    
    try:
        summary = create_evaluation_dataset(
            config_path=args.config,
            output_dir=args.output,
            num_augmentations=args.num_augmentations
        )
        
        print("\nğŸ‰ Dataset creation completed successfully!")
        
    except Exception as e:
        print(f"\nâŒ Error during dataset creation: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
