#!/usr/bin/env python3
"""
Script ki·ªÉm tra c·∫•u h√¨nh GPU v√† th√¥ng tin h·ªá th·ªëng
"""

import torch
import torch.nn as nn
import subprocess
import sys

def check_gpu_info():
    """Ki·ªÉm tra th√¥ng tin GPU"""
    print("üîç KI·ªÇM TRA TH√îNG TIN GPU")
    print("=" * 50)
    
    # Ki·ªÉm tra CUDA availability
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        print(f"‚úÖ CUDA c√≥ s·∫µn: {gpu_count} GPU(s)")
        
        # Th√¥ng tin chi ti·∫øt t·ª´ng GPU
        for i in range(gpu_count):
            gpu_name = torch.cuda.get_device_name(i)
            gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)
            print(f"   GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)")
        
        # Ki·ªÉm tra memory hi·ªán t·∫°i
        print(f"\nüìä MEMORY USAGE:")
        for i in range(gpu_count):
            torch.cuda.set_device(i)
            allocated = torch.cuda.memory_allocated(i) / (1024**3)
            reserved = torch.cuda.memory_reserved(i) / (1024**3)
            print(f"   GPU {i}: Allocated={allocated:.2f}GB, Reserved={reserved:.2f}GB")
    else:
        print("‚ùå CUDA kh√¥ng c√≥ s·∫µn")
        return False
    
    return True

def check_multi_gpu_capabilities():
    """Ki·ªÉm tra kh·∫£ nƒÉng multi-GPU"""
    print("\nüöÄ KI·ªÇM TRA KH·∫¢ NƒÇNG MULTI-GPU")
    print("=" * 50)
    
    if not torch.cuda.is_available():
        print("‚ùå CUDA kh√¥ng c√≥ s·∫µn")
        return False
    
    gpu_count = torch.cuda.device_count()
    if gpu_count < 2:
        print(f"‚ö†Ô∏è  Ch·ªâ c√≥ {gpu_count} GPU - Kh√¥ng th·ªÉ ch·∫°y multi-GPU")
        return False
    
    print(f"‚úÖ C√≥ {gpu_count} GPU - C√≥ th·ªÉ ch·∫°y multi-GPU")
    
    # Test DataParallel
    try:
        print("\nüß™ Testing DataParallel...")
        model = nn.Linear(10, 1)
        model = nn.DataParallel(model)
        model.cuda()
        
        # Test input
        x = torch.randn(4, 10).cuda()
        output = model(x)
        print(f"‚úÖ DataParallel test th√†nh c√¥ng: input_shape={x.shape}, output_shape={output.shape}")
        
        # Test SyncBatchNorm
        print("\nüîÑ Testing SyncBatchNorm...")
        model = nn.BatchNorm1d(10)
        model = nn.SyncBatchNorm.convert_sync_batchnorm(model)
        model = nn.DataParallel(model)
        model.cuda()
        
        x = torch.randn(4, 10).cuda()
        output = model(x)
        print(f"‚úÖ SyncBatchNorm test th√†nh c√¥ng: input_shape={x.shape}, output_shape={output.shape}")
        
    except Exception as e:
        print(f"‚ùå Multi-GPU test th·∫•t b·∫°i: {e}")
        return False
    
    return True

def check_system_info():
    """Ki·ªÉm tra th√¥ng tin h·ªá th·ªëng"""
    print("\nüíª TH√îNG TIN H·ªÜ TH·ªêNG")
    print("=" * 50)
    
    # Python version
    print(f"üêç Python version: {sys.version}")
    
    # PyTorch version
    print(f"üî• PyTorch version: {torch.__version__}")
    
    # CUDA version
    if torch.cuda.is_available():
        print(f"‚ö° CUDA version: {torch.version.cuda}")
        print(f"üèóÔ∏è  cuDNN version: {torch.backends.cudnn.version()}")
    
    # CPU info
    try:
        import multiprocessing
        cpu_count = multiprocessing.cpu_count()
        print(f"üíæ CPU cores: {cpu_count}")
    except:
        print("üíæ CPU cores: Unknown")
    
    # Memory info
    try:
        import psutil
        memory = psutil.virtual_memory()
        print(f"üß† RAM: {memory.total / (1024**3):.1f} GB (available: {memory.available / (1024**3):.1f} GB)")
    except ImportError:
        print("üß† RAM: Unknown (install psutil for memory info)")

def main():
    print("üîß KI·ªÇM TRA C·∫§U H√åNH MULTI-GPU TRAINING")
    print("=" * 60)
    
    # Check system info
    check_system_info()
    
    # Check GPU info
    gpu_available = check_gpu_info()
    
    if gpu_available:
        multi_gpu_ready = check_multi_gpu_capabilities()
        
        print("\n" + "=" * 60)
        print("üìã K·∫æT LU·∫¨N:")
        if multi_gpu_ready:
            print("‚úÖ H·ªá th·ªëng S·∫¥N S√ÄNG cho multi-GPU training!")
            print("üöÄ C√≥ th·ªÉ ch·∫°y: bash train_multi_gpu.sh")
        else:
            print("‚ö†Ô∏è  H·ªá th·ªëng ch·ªâ h·ªó tr·ª£ single-GPU training")
            print("üî• C√≥ th·ªÉ ch·∫°y: python train.py --config configs/dinov2_vitb14.yaml")
    else:
        print("\n" + "=" * 60)
        print("üìã K·∫æT LU·∫¨N:")
        print("‚ùå H·ªá th·ªëng ch·ªâ h·ªó tr·ª£ CPU training")
        print("üíª C√≥ th·ªÉ ch·∫°y: python train.py --config configs/dinov2_vitb14.yaml")

if __name__ == "__main__":
    main()
